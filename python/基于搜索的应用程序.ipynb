{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import time\n",
    "import datetime\n",
    "import bisect\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = redis.Redis(decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set('''able about across after all almost also am among\n",
    "an and any are as at be because been but by can cannot could dear did\n",
    "do does either else ever every for from get got had has have he her\n",
    "hers him his how however if in into is it its just least let like\n",
    "likely may me might most must my neither no nor not of off often on\n",
    "only or other our own rather said say says she should since so some\n",
    "than that the their them then there these they this tis to too twas us\n",
    "wants was we were what when where which while who whom why will with\n",
    "would yet you your'''.split()) \n",
    "WORDS_RE = re.compile(\"[a-z']{2,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(content):\n",
    "    words = set()\n",
    "    for match in WORDS_RE.finditer(content.lower()):\n",
    "        word = match.group().strip(\"'\")\n",
    "        if len(word) > 2:\n",
    "            words.add(word)\n",
    "    return words - STOP_WORDS\n",
    "\n",
    "def index_document(conn, docid, content):\n",
    "    words = tokenize(content)\n",
    "    pipe = conn.pipeline(True)\n",
    "    for word in words:\n",
    "        pipe.sadd('idx:'+word, docid)\n",
    "    return len(pipe.execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_common(conn, method, names, ttl=30, execute=True):\n",
    "    id = str(uuid.uuid4())\n",
    "    pipe = conn.pipeline(True) if execute else conn\n",
    "    names = ['idx:'+name for name in names]\n",
    "    getattr(pipe, method)('idx:'+id, *names)\n",
    "    pipe.expire('idx:'+id, ttl)\n",
    "    if execute:\n",
    "        pipe.execute()\n",
    "    return id\n",
    "\n",
    "# 交集\n",
    "def intersect(conn, items, ttl=30, _execute=True):\n",
    "    return _set_common(conn, 'sinterstore', items, ttl, _execute)\n",
    "\n",
    "# 并集\n",
    "def union(conn, items, ttl=30, _execute=True):\n",
    "    return _set_common(conn, 'sunionstore', items, ttl, _execute)\n",
    "\n",
    "# 差集\n",
    "def difference(conn, item, ttl=30, _execute=True):\n",
    "    return _set_common(conn, 'sdiffstore', items, ttl, _execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_RE = re.compile(\"[+-]?[a-z']{2,}\")\n",
    "\n",
    "def parse(query):\n",
    "    unwatched = set()\n",
    "    all = []\n",
    "    current = set()\n",
    "    for match in QUERY_RE.finditer(query.lower()):\n",
    "        word = match.group()\n",
    "        prefix = word[:1]\n",
    "        if prefix in '+-':\n",
    "            word = word[1:]\n",
    "        else:\n",
    "            prefix = None\n",
    "        word = word.strip(\"'\")\n",
    "        if len(word) < 2 or word in STOP_WORDS:\n",
    "            continue\n",
    "        if prefix == '-':\n",
    "            unwatched.add(word)\n",
    "            continue\n",
    "        if current and not prefix:\n",
    "            all.append(list(current))\n",
    "            current = set()\n",
    "        current.add(word)\n",
    "    if current:\n",
    "        all.append(list(current))\n",
    "    return all, list(unwatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['conect', 'disconnect', 'connection'], ['chat']], ['proxies', 'proxy'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse('''\n",
    "conect +connection +disconnect +disconnect\n",
    "chat\n",
    "-proxy -proxies\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_search(conn, query, ttl=30):\n",
    "    all, unwatched = parse(query)\n",
    "    if not all:\n",
    "        return None\n",
    "    to_intersect = []\n",
    "    for syn in all:\n",
    "        if len(syn) > 1:\n",
    "            to_intersect.append(union(conn, syn, ttl=ttl))\n",
    "        else:\n",
    "            to_intersect.append(syn[0])\n",
    "        \n",
    "        if len(to_intersect) > 1:\n",
    "            intersect_result = intersect(conn, to_intersect, ttl=ttl)\n",
    "        else:\n",
    "            intersect_result = to_intersect[0]\n",
    "        \n",
    "        if unwatched:\n",
    "            unwatched.insert(0, intersect_result)\n",
    "            return difference(conn, unwatched, ttl=ttl)\n",
    "        return intersect_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_document(conn, 'doc1', '''#B Set up a transactional pipeline so that we have consistent results for each individual call\n",
    "#C Add the 'idx:' prefix to our terms\n",
    "#D Set up the call for one of the operations\n",
    "#E Instruct Redis to expire the SET in the future\n",
    "#F Actually execute the operation\n",
    "#G Return the id for the caller to process the results\n",
    "#H Helper function to perform SET intersections\n",
    "#I Helper function to perform SET unions\n",
    "#J Helper function to perform SET differences''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_document(conn, 'doc2', '''#A Our regular expression for finding wanted, unwanted, and synonym words\n",
    "#B A unique set of unwanted words Return\n",
    "#C Our final result of words that we are looking to intersect\n",
    "#D The current unique set of words to consider as synonyms\n",
    "#E Iterate over all words in the search query\n",
    "#F Discover +/- prefixes, if any\n",
    "#G Strip any leading or trailing single quotes, and skip anything that is a stop word\n",
    "#H If the word is unwanted, add it to the unwanted set\n",
    "#I Set up a new synonym set if we have no synonym prefix and we already have words\n",
    "#J Add the current word to the current set\n",
    "#K Add any remaining words to the final intersection\n",
    "#END''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4368b4e8-45e6-4b0d-9227-62aa0a097170'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_and_search(conn,'current +unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc2'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.smembers('idx:4368b4e8-45e6-4b0d-9227-62aa0a097170')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_sort(conn, query, id=None, ttl=300, sort='-updated',\n",
    "                   start=0, num=20):\n",
    "    desc = sort.startswith('-')\n",
    "    sort = sort.lstrip('-')\n",
    "    by = 'kb:doc:*->' + sort\n",
    "    alpha = sort not in ('updated', 'id', 'created')\n",
    "    if id and not conn.expire(id, ttl):\n",
    "        id = None\n",
    "    if not id:\n",
    "        id = parse_and_search(conn, query, ttl=ttl)\n",
    "        \n",
    "    pipe = conn.pipeline(True)\n",
    "    pipe.scard('idx:'+id)\n",
    "    pipe.sort('idx:'+id, by=by, alpha=alpha, desc=desc, \n",
    "              start=start, num=num)\n",
    "    results = pipe.execute()\n",
    "    return results[0], results[1], id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, ['doc2'], 'e01e4a3c-d63e-438b-9903-54d4488977ec')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_and_sort(conn,'current +unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有序索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zset_common(conn, method, scores, ttl=30, **kw):\n",
    "    id = str(uuid.uuid4())\n",
    "    execute = kw.pop('_execute', True)\n",
    "    pipe = conn.pipeline(True) if execute else conn\n",
    "    for key in scores.keys():\n",
    "        scores['idx:'+key] = scores.pop(key)\n",
    "    print(scores)\n",
    "    getattr(pipe, method)('idx:'+id, scores, **kw)\n",
    "    pipe.expire('idx:'+id, ttl)\n",
    "    if execute:\n",
    "        pipe.execute()\n",
    "    return id\n",
    "\n",
    "def zintersect(conn, items, ttl=30, **kw):\n",
    "    return _zset_common(conn, 'zinterstore', dict(items), ttl, **kw)\n",
    "\n",
    "def zunion(conn, items, ttl=30, **kw):\n",
    "    return _zset_common(conn, 'zunionstore', dict(items), ttl, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_zsort(conn, query, id=None, ttl=300, update=1,\n",
    "                    vote=0, start=0, num=20, desc=True):\n",
    "    if id and not conn.expire(id, ttl):\n",
    "        id = None\n",
    "    if not id:\n",
    "        id = parse_and_search(conn, query, ttl=ttl)\n",
    "        scored_search = {\n",
    "            id: 0,\n",
    "            'sort:update': update,\n",
    "            'sort:votes': vote\n",
    "        }\n",
    "        id = zintersect(conn, scored_search, ttl)\n",
    "    \n",
    "    pipe = conn.pipeline(True)\n",
    "    pipe.zcard('idx:'+id)\n",
    "    if desc:\n",
    "        pipe.zrevrange('idx:'+id, start, start+num-1)\n",
    "    else:\n",
    "        pipe.zrange('idx:'+id, start, start+num-1)\n",
    "    results = pipe.execute()\n",
    "    return results[0], results[1], id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, ['doc2', 'doc1'], '469ea137-5588-4749-8c5a-07708ba4f720')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.zadd('idx:sort:update', {'doc1': 1, 'doc2': 10})\n",
    "conn.zadd('idx:sort:votes', {'doc1': 10, 'doc2': 1})\n",
    "search_and_zsort(conn,'set +return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.zinterstore('test', dict({'idx:c83c4224-fcdc-457f-b08c-199320752e8f': 0, 'idx:sort:update': 1, 'idx:sort:votes': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.zrange('test',0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.zinterstore('test',{'id':1,'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
